{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi Sentiment Analysis for Hindi Text\n",
    "\n",
    "### Introduction\n",
    "In this Sentiment Analysis project we will take dataset of movie reviews in English and use it to train the Model. And then we will take manual inputs in Hindi Language and use the trained model to predict the sentiment of the manual input as positive or negative. We have used NLTK(Natural Language ToolKit) and SKLearn(Scikit Learn) for the preprocessing and model training. Due to lack of sufficient dataset in Hindi language, the model is trained on English dataset and the testing is done on the Hindi inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "Engish dataset, stored in 'movie_review.csv', is read by using pandas. Unnecessary columns are dropped and it is stored in MR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "MR = pd.read_csv('movie_review.csv')\n",
    "MR = MR.drop(['fold_id','cv_tag','html_id','sent_id'],axis = 1)   #MR is movie review which is having 2 columns one is text and other is their polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  tag\n",
      "0  films adapted from comic books have had plenty...  pos\n",
      "1  for starters , it was created by alan moore ( ...  pos\n",
      "2  to say moore and campbell thoroughly researche...  pos\n",
      "                                                    text  tag\n",
      "48152  we all know that inter-office politics are jus...  neg\n",
      "21036  the story and acting are of good quality , but...  pos\n",
      "30937  a fine film , even though it needs just a litt...  pos\n",
      "(64720, 2)\n"
     ]
    }
   ],
   "source": [
    "print(MR.head(3))\n",
    "MR  = MR.sample(frac=1)\n",
    "print(MR.head(3))\n",
    "print(MR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Preprocessing of data is done in this section which includes:<br>\n",
    "1. Converting into lower case\n",
    "2. Removing punctuations<br>\n",
    "3. Removing numbers\n",
    "4. Removing white spaces\n",
    "5. Removing stop words\n",
    "6. Using Lemmatizer\n",
    "7. Stemming the words using **Porter Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_file,target):\n",
    "    import re\n",
    "    import string\n",
    "    \n",
    "    #Convert All into Lower Case\n",
    "    input_file[target] = input_file[target].str.lower()\n",
    "    \n",
    "    #Removing Punctuation\n",
    "    input_file[target] = input_file[target].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    \n",
    "    #Removing Numbers\n",
    "    input_file[target] = input_file[target].str.replace('\\d+', '')\n",
    "\n",
    "    #Removing White Spaces\n",
    "    input_file[target] = input_file[target].str.strip()\n",
    "    \n",
    "    #Tokenization\n",
    "    #Removal of Stop Words\n",
    "    from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.stem import PorterStemmer\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stemmer= PorterStemmer()\n",
    "        \n",
    "        \n",
    "    \n",
    "    tokenized = input_file[target].apply(lambda p: p.split())\n",
    "    print(tokenized[0])\n",
    "    print(type(tokenized))\n",
    "    for i in range(tokenized.size):\n",
    "        result = [j for j in tokenized[i] if not j in ENGLISH_STOP_WORDS]\n",
    "        tokenized[i] = result\n",
    "        \n",
    "    #tokenized = tokenized.apply(lambda p: [for i in p if not in i in ENGLISH_STOP_WORDS])\n",
    "    tokenized = tokenized.apply(lambda p: [lemmatizer.lemmatize(i) for i in p])\n",
    "    tokenized = tokenized.apply(lambda p : [stemmer.stem(i) for i in p])\n",
    "    for i in range(len(tokenized)):\n",
    "        tokenized[i] = ' '.join(tokenized[i])\n",
    "    input_file[target] = tokenized\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  tag\n",
      "48152  we all know that inter-office politics are jus...  neg\n",
      "21036  the story and acting are of good quality , but...  pos\n",
      "30937  a fine film , even though it needs just a litt...  pos\n",
      "55162  for example , the two gym teachers , mrs . bal...  neg\n",
      "6554   one of the most overlooked aspects of this fil...  pos\n",
      "45894  even after that happens , though , i'll still ...  neg\n",
      "6995                         but it's us being clapped .  pos\n",
      "61306  the next day , the team wakes up and discovers...  neg\n",
      "20209  this is because few moviegoers will care a who...  pos\n",
      "20810  not coincidentally he was something of a mysti...  pos\n",
      "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', 'whether', 'they', 're', 'about', 'superheroes', 'batman', 'superman', 'spawn', 'or', 'geared', 'toward', 'kids', 'casper', 'or', 'the', 'arthouse', 'crowd', 'ghost', 'world', 'but', 'there', 's', 'never', 'really', 'been', 'a', 'comic', 'book', 'like', 'from', 'hell', 'before']\n",
      "<class 'pandas.core.series.Series'>\n",
      "                                                    text  tag\n",
      "48152                  know inter offic polit just polit  neg\n",
      "21036      stori act good qualiti s sens authent realiti  pos\n",
      "30937  fine film need just littl kind film recommend ...  pos\n",
      "55162  exampl gym teacher mr balbrick nanci parson ho...  neg\n",
      "6554   overlook aspect film music compos cameron regu...  pos\n",
      "45894            happen ll consid iren high calib misfir  neg\n",
      "6995                                              s clap  pos\n",
      "61306  day team wake discov camera equip complet tras...  neg\n",
      "20209  moviego care lot guy leisur suit terri cloth s...  pos\n",
      "20810         coincident mystic regularli assail passion  pos\n",
      "(64720, 2)\n"
     ]
    }
   ],
   "source": [
    "print(MR.head(10))\n",
    "preprocessing(MR,'text')\n",
    "print(MR.head(10))\n",
    "print(MR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction:\n",
    "TF-IDF technique is used for the feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(input_file,target):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    tfidfV = TfidfVectorizer(max_df = 0.9,min_df = 2,max_features = 800, stop_words = 'english')\n",
    "    vecTor=  tfidfV.fit_transform(input_file[target])\n",
    "    return vecTor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64720, 800)\n",
      "  (0, 369)\t0.2984188631924792\n",
      "  (0, 472)\t0.3909773470549727\n",
      "  (0, 509)\t0.8313382857158736\n",
      "  (0, 360)\t0.2587654360299233\n",
      "  (1, 661)\t0.32032734776899585\n",
      "  (1, 5)\t0.3731434813516857\n",
      "  (1, 284)\t0.3166009896379076\n",
      "  (1, 536)\t0.4847380998638775\n",
      "  (1, 606)\t0.42274466027904917\n",
      "  (1, 547)\t0.49420043778029105\n",
      "  (2, 360)\t0.2743690457463526\n",
      "  (2, 256)\t0.4247667417167444\n",
      "  (2, 253)\t0.37833423216775036\n",
      "  (2, 457)\t0.3719538013852179\n",
      "  (2, 394)\t0.31865770770307894\n",
      "  (2, 366)\t0.3782478595598175\n",
      "  (2, 552)\t0.46711266556638864\n",
      "  (3, 221)\t0.5016957606367182\n",
      "  (3, 449)\t0.4865932780464587\n",
      "  (3, 535)\t0.5502151205297771\n",
      "  (3, 269)\t0.45693726775078153\n",
      "  (4, 253)\t0.2183621220828705\n",
      "  (4, 41)\t0.5124813057051281\n",
      "  (4, 452)\t0.4325988334773524\n",
      "  (4, 87)\t0.5367837823481592\n",
      "  :\t:\n",
      "  (64713, 376)\t0.4544799690680784\n",
      "  (64714, 546)\t1.0\n",
      "  (64715, 253)\t0.3015469049429314\n",
      "  (64715, 475)\t0.5897265992852079\n",
      "  (64715, 797)\t0.4934358839568921\n",
      "  (64715, 474)\t0.5637490848227809\n",
      "  (64716, 57)\t0.7102887236490734\n",
      "  (64716, 232)\t0.7039104552831775\n",
      "  (64717, 146)\t0.7433389304861093\n",
      "  (64717, 142)\t0.6689149680069709\n",
      "  (64718, 284)\t0.23682128797988894\n",
      "  (64718, 253)\t0.15642662131474774\n",
      "  (64718, 391)\t0.2091139805369618\n",
      "  (64718, 270)\t0.29573534649122796\n",
      "  (64718, 399)\t0.25090994764121644\n",
      "  (64718, 50)\t0.2681916012260044\n",
      "  (64718, 728)\t0.808316646426271\n",
      "  (64719, 448)\t0.4178499992048366\n",
      "  (64719, 7)\t0.31540922076665723\n",
      "  (64719, 103)\t0.24539445657187314\n",
      "  (64719, 599)\t0.33977131235666713\n",
      "  (64719, 25)\t0.4368242507875074\n",
      "  (64719, 549)\t0.30251203910358065\n",
      "  (64719, 410)\t0.3083769429782091\n",
      "  (64719, 101)\t0.41572841948061734\n"
     ]
    }
   ],
   "source": [
    "Xtrain = feature_extraction(MR,'text')\n",
    "print(Xtrain.shape)\n",
    "print(Xtrain)\n",
    "#print(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Ytrain = []\n",
    "for i in MR['tag']:\n",
    "    if str(i) == 'pos':\n",
    "        Ytrain.append(1)\n",
    "    else:\n",
    "        Ytrain.append(0)\n",
    "#print(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the model\n",
    "Model has been trained by using Decision Tree Algorithm. Inbuilt library of Scikit Learn is used for implementing **Decision Tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.metrics import *\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "model = DT()\n",
    "X_train,X_test,Y_train,Y_test = TTS(Xtrain,Ytrain,test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531314379892872\n"
     ]
    }
   ],
   "source": [
    "prid = model.predict(X_test)\n",
    "print(accuracy_score(Y_test,prid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Input in Hindi\n",
    "Here we are taking the input in Hindi language. The input is then preprocessed and given to the trained model. We will get output as positive and negative from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalConversion(get_inp):\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    get_inp = translator.translate(text = get_inp,dest = 'en',src = 'hi')\n",
    "    get_inp = get_inp.text\n",
    "    print(get_inp)\n",
    "    df1 = pd.DataFrame({'text':[get_inp],'tag':[0]})\n",
    "    new_df = MR\n",
    "    df1 = df1.append(new_df,ignore_index = True)\n",
    "    preprocessing(df1,'text')\n",
    "    tstVec = feature_extraction(df1,'text')\n",
    "    v = tstVec[1]\n",
    "    x = model.predict(v)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text in Hindi: एबीसीडी 2’ में ड्रामा की कमी है, इस कमी की वजह से ही सुरु और विन्नी का रोमांस भी नहीं उभर पाता।\n",
      "ABCD 2 'lack of drama, due to the reduction does not emerge romance of Suru and Vinny.\n",
      "\n",
      "Prediction is: Positive\n"
     ]
    }
   ],
   "source": [
    "get_inp = input(\"Enter Text in Hindi: \")\n",
    "output = finalConversion(get_inp)\n",
    "if output == 0:\n",
    "    output = \"Negative\"\n",
    "else:\n",
    "    output = \"Positive\"\n",
    "print(\"\\nPrediction is: \" +output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# भाऊत अच्छी मूवी है ये!\n",
    "# एबीसीडी 2’ में ड्रामा की कमी है, इस कमी की वजह से ही सुरु और विन्नी का रोमांस भी नहीं उभर पाता।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
